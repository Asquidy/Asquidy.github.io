---
layout: 
title: "News from Generative Artificial Intelligence is Believed Less"
abstract: Artificial Intelligence (AI) can generate text virtually indistinguishable from text written by humans. A key question, then, is whether people believe news generated by AI as much as news generated by humans. AI is viewed as lacking human motives and emotions, suggesting that people might view news written by AI as more accurate. By contrast, two pre-registered experiments on representative U.S. samples (N=4,034) showed that people rated news written by AI as less accurate than news written by humans. People were more likely to incorrectly rate news written by AI (vs. a human) as inaccurate when it was actually true, and more likely to correctly rate it as inaccurate when it was indeed false. Our findings are important given the increasing adoption of AI in news generation, and the associated ethical and governance pressures to disclose it use and address standards of transparency and accountability.
category: research
journal:  Fairness, Accountability, and Transparency (ACM FAccT 2022)
link: "https://dl.acm.org/doi/pdf/10.1145/3531146.3533077"
coauthors: with Chiara Longoni, Luca Cian, and Gordon Pennycook
js: "toggleMe('ainews'); return false;"
js_abbrev: 'ainews'
order: 11
published: 2
trueyear: 2022
bibjs: "toggleMe('ainews_bib'); return false;"
bib_abbrev: 'ainews_bib'
---
